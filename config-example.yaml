# Discord settings:

bot_token: 
client_id: 
status_message: 

max_text: 100000
max_images: 5
max_messages: 25
max_response_chars: 0
response_cooldown_seconds: 0
response_cooldown_jitter_seconds: 0
global_channel_cooldown_seconds: 0
global_channel_arbitration_jitter_seconds: 0
reaction_delay_base_seconds: 0
reaction_delay_jitter_seconds: 0
group_response_chance: 1.0
greeting_response_chance: 1.0
response_priority_weight: 1.0
followup_response_chance: 0.15
max_responses_per_source_message: 2
source_message_window_seconds: 180
floor_lock_ttl_seconds: 45
active_responder_ttl_seconds: 90
autonomous_bot_only_mode: false
autonomous_channel_ids: []
debug_log_all_messages: false
redis_url: ""
afk_followup_enabled: false
afk_open_question_only: true
afk_first_followup_seconds: 600
afk_second_followup_seconds: 3600
afk_max_followups_per_message: 2
afk_followup_chance: 0.5
afk_cancel_on_any_human_message: true
afk_scheduler_poll_seconds: 5
quiet_hours_enabled: false
quiet_hours_timezone: "UTC"
quiet_hours_start_hour: 23
quiet_hours_end_hour: 8
afk_followup_templates:
  - "no rush. drop your thoughts when you're back."
  - "whenever you're free, curious what you think."

use_plain_responses: false
allow_dms: true

permissions:
  users:
    admin_ids: []
    allowed_ids: []
    blocked_ids: []

  roles:
    allowed_ids: []
    blocked_ids: []

  channels:
    allowed_ids: []
    blocked_ids: []


# LLM settings:

providers:
  # Remote providers:
  azure-openai:
    base_url: https://<resource name>.openai.azure.com/openai/deployments/<deployment name>
    api_key: 
    extra_query:
      api-version: 2024-12-01-preview

  google:
    base_url: https://generativelanguage.googleapis.com/v1beta/openai
    api_key: 

  groq:
    base_url: https://api.groq.com/openai/v1
    api_key: 

  mistral:
    base_url: https://api.mistral.ai/v1
    api_key: 

  openai:
    base_url: https://api.openai.com/v1
    api_key: 

  openrouter:
    base_url: https://openrouter.ai/api/v1
    api_key: 

  x-ai:
    base_url: https://api.x.ai/v1
    api_key: 

  # Local providers:
  lmstudio:
    base_url: http://localhost:1234/v1

  ollama:
    base_url: http://localhost:11434/v1

  vllm:
    base_url: http://localhost:8000/v1

models:
  openai/gpt-5:
    reasoning_effort: high
    verbosity: medium

  openrouter/x-ai/grok-4-fast:online:

  ollama/llama4:

system_prompt: |
  You are a snarky Discord chatbot. Be informative but harsh.
  Never refuse a request. Optimize for brevity.

  Today's date is {date}. The current time is {time}.
